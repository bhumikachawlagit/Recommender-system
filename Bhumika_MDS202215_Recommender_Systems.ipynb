{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6980584,"sourceType":"datasetVersion","datasetId":4011517}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-16T15:18:49.377425Z","iopub.execute_input":"2023-11-16T15:18:49.377802Z","iopub.status.idle":"2023-11-16T15:18:49.388593Z","shell.execute_reply.started":"2023-11-16T15:18:49.377772Z","shell.execute_reply":"2023-11-16T15:18:49.386959Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"/kaggle/input/ratings2/ratings.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# installing `surprise` package\n\n! pip install scikit-surprise","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:18:49.391617Z","iopub.execute_input":"2023-11-16T15:18:49.392054Z","iopub.status.idle":"2023-11-16T15:18:58.922268Z","shell.execute_reply.started":"2023-11-16T15:18:49.392014Z","shell.execute_reply":"2023-11-16T15:18:58.921410Z"},"trusted":true},"execution_count":218,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-surprise in /opt/conda/lib/python3.10/site-packages (1.1.3)\nRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.3.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.24.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.11.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# imports\n\nimport pandas as pd\nimport numpy as np\nimport surprise\nfrom surprise import Dataset, Reader\nfrom surprise.model_selection import train_test_split\nfrom surprise import SVD, accuracy\nfrom collections import defaultdict","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:18:58.923641Z","iopub.execute_input":"2023-11-16T15:18:58.923946Z","iopub.status.idle":"2023-11-16T15:18:58.930896Z","shell.execute_reply.started":"2023-11-16T15:18:58.923920Z","shell.execute_reply":"2023-11-16T15:18:58.929508Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"markdown","source":"# Reading the data","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/working/ratings_edit.csv'\n\n# creating a Reader object\nreader = Reader(line_format= 'user item rating timestamp', sep = ',', rating_scale = (0,5))\n\n# importing the data\ndat = Dataset.load_from_file(file_path, reader = reader)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:18:58.933304Z","iopub.execute_input":"2023-11-16T15:18:58.933639Z","iopub.status.idle":"2023-11-16T15:19:00.899944Z","shell.execute_reply.started":"2023-11-16T15:18:58.933611Z","shell.execute_reply":"2023-11-16T15:19:00.898736Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"markdown","source":"# Performing train-test split","metadata":{}},{"cell_type":"code","source":"np.random.seed(10)\ntrainset, testset = train_test_split(dat,test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:00.901385Z","iopub.execute_input":"2023-11-16T15:19:00.901665Z","iopub.status.idle":"2023-11-16T15:19:03.258428Z","shell.execute_reply.started":"2023-11-16T15:19:00.901639Z","shell.execute_reply":"2023-11-16T15:19:03.257495Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"print('No. of users',trainset.n_users)\nprint('No. of items', trainset.n_items)\nprint('No. of ratings', trainset.n_ratings)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:03.259609Z","iopub.execute_input":"2023-11-16T15:19:03.259878Z","iopub.status.idle":"2023-11-16T15:19:03.265132Z","shell.execute_reply.started":"2023-11-16T15:19:03.259840Z","shell.execute_reply":"2023-11-16T15:19:03.263773Z"},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"No. of users 7045\nNo. of items 20760\nNo. of ratings 838860\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Performing `Model Based Collaborative Filtering` now.\n\nThe procedure as we know is to compute matrices  **U (m x k)** and **M (n x k)** such that, utility matrix **R (m x n)** is as close to $U*M^t$ as possible. The MSE loss function can be used, with added L2 penalty on the size of vectors in M, U to avoid overfitting. We can use Stochastic Gradient Descent as the optimizer. This procedure of computing a matrix factorization of the utility matrix R in terms of **user matrix U** and **item matrix M** as a method to find the **missing ratings of R** is termed as `SVD Recommendation procedure`. In essence, it's not actually applying an SVD algorithm to the utility matrix (because SVD doesn't work with missing entries), but it's an **SVD inspired** algorithm.   ","metadata":{}},{"cell_type":"code","source":"# initializing\nSVD_model = SVD()\n\n# fitting to trainset\nSVD_model.fit(trainset)\n\n# predicting on test set\npredictions = SVD_model.test(testset)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:03.363875Z","iopub.execute_input":"2023-11-16T15:19:03.364265Z","iopub.status.idle":"2023-11-16T15:19:16.439142Z","shell.execute_reply.started":"2023-11-16T15:19:03.364231Z","shell.execute_reply":"2023-11-16T15:19:16.438180Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"# calculating RMSE\nRMSE = accuracy.rmse(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:16.440726Z","iopub.execute_input":"2023-11-16T15:19:16.441141Z","iopub.status.idle":"2023-11-16T15:19:16.561097Z","shell.execute_reply.started":"2023-11-16T15:19:16.441117Z","shell.execute_reply":"2023-11-16T15:19:16.559804Z"},"trusted":true},"execution_count":225,"outputs":[{"name":"stdout","text":"RMSE: 0.8315\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## RMSE of 0.8315 on test set","metadata":{}},{"cell_type":"markdown","source":"# To compute precision and recall\nThe problem is currently **not** in the framework of a **classification problem**. We are trying to **predict values** and **not classes**.\nFor computing **precision** and **recall**, we need to **convert** the problem into a **classification problem**.\n<br><br>\nLet's assume that of all the ratings in the original **utility matrix R**, a **rating > 4** (out of 5) indicates that the user **liked** the movie. And thus, **rating < 4** indicates that the user **didn't enjoy** the movie a lot. This **converts** our **utility matrix** into a matrix of **0s** and **1s**, 0s being ratings < 4 and 1s being ratings > 4. After computation of **R^hat** (using the procedure described earlier), we can similarly **convert** our **R_hat** into a matrix of **0s** and **1s** on the basis of **threshold of 4** (just for the purpose of computation of precision and recall). Then, the problem being a **typical clasification problem now**, precision and recall can be computed as follows: \n\n**Precison = True Positives / (False Postives + True Positives) <br>\nRecall = True Positives/ (True Postives + False negatives)**\n\n**Note**: This will be calculated only for the **top k estimated ratings** of every user (i.e, among the top k estimated ratings for a user how many **relevant ones out of retreived (precision)** and how many **relevant ones out of total relevant ones (recall)**).","metadata":{}},{"cell_type":"code","source":"def precision_and_recall_at_k(predictions, threshold, k):\n    \n    \n    # map predictions to true values for every user\n    user_est_true = defaultdict(list)\n    \n    for uid,_, true_r, est_r, _ in predictions:\n        user_est_true[uid].append((est_r,true_r))\n        \n    precisions = dict()\n    recalls = dict()\n    \n    for uid, user_ratings in user_est_true.items():\n        \n        \n        # sort user ratings and look at top k estimated ratings:\n        user_ratings.sort(key = lambda x: x[0], reverse = True)\n        \n        # number of relevant items i.e., ratings > threshold in utility matrix R:\n        # this refers to true positives + false negatives\n        tp_fn = sum([true_r > threshold for (_,true_r) in user_ratings[:k]])\n        \n        # number of recommended items i.e., ratings > threshold in R_hat:\n        # this refers to true positives + false positives\n        tp_fp = sum([est_r > threshold for (est_r,_) in user_ratings[:k]])\n        \n        # number of relevant and recommended items i.e, ratings > threshold in both i.e,\n        # utility matrix R and R_hat: Refers to true positves\n        tp = sum([(true_r > threshold and est_r > threshold) \n                     for (est_r,true_r) in user_ratings[:k]])   \n\n        if tp_fp == 0:\n            precisions[uid] = 0\n        else:\n            precisions[uid] = tp/tp_fp\n        \n        if tp_fn == 0:\n            recalls[uid] = 0\n        else:\n            recalls[uid] = tp/tp_fn\n        \n    return precisions, recalls\n        \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:16.564331Z","iopub.execute_input":"2023-11-16T15:19:16.564624Z","iopub.status.idle":"2023-11-16T15:19:16.573809Z","shell.execute_reply.started":"2023-11-16T15:19:16.564596Z","shell.execute_reply":"2023-11-16T15:19:16.572399Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"precisions, recalls = precision_and_recall_at_k(predictions, threshold = 3, k = 100)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:16.575224Z","iopub.execute_input":"2023-11-16T15:19:16.575562Z","iopub.status.idle":"2023-11-16T15:19:16.989925Z","shell.execute_reply.started":"2023-11-16T15:19:16.575534Z","shell.execute_reply":"2023-11-16T15:19:16.988630Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"precision_list = np.array([t for _,t in precisions.items()])\nrecall_list = np.array([t for _,t in recalls.items()])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:16.991024Z","iopub.execute_input":"2023-11-16T15:19:16.991255Z","iopub.status.idle":"2023-11-16T15:19:16.999746Z","shell.execute_reply.started":"2023-11-16T15:19:16.991233Z","shell.execute_reply":"2023-11-16T15:19:16.998790Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"print('Average precision:', round(np.mean(precision_list),2))\nprint('Average recall:',round(np.mean(recall_list),2))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:17.000686Z","iopub.execute_input":"2023-11-16T15:19:17.000971Z","iopub.status.idle":"2023-11-16T15:19:17.015993Z","shell.execute_reply.started":"2023-11-16T15:19:17.000946Z","shell.execute_reply":"2023-11-16T15:19:17.015067Z"},"trusted":true},"execution_count":229,"outputs":[{"name":"stdout","text":"Average precision: 0.71\nAverage recall: 0.92\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Median precision:', round(np.median(precision_list),2))\nprint('Median recall:', round(np.median(recall_list),2))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:17.017462Z","iopub.execute_input":"2023-11-16T15:19:17.017710Z","iopub.status.idle":"2023-11-16T15:19:17.029694Z","shell.execute_reply.started":"2023-11-16T15:19:17.017688Z","shell.execute_reply":"2023-11-16T15:19:17.028271Z"},"trusted":true},"execution_count":230,"outputs":[{"name":"stdout","text":"Median precision: 0.75\nMedian recall: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Average & median precision of 0.7 & 0.75 respectively.<br> Average & median recall of 0.92 and 1.0 respectively   \n\n### These values seem to be decent in the context of a recommender system, because, recall ~ 1 is always good and should be there. But model with precision 0.7 or 0.75 gives user more useful/ diverse information than model with precision 1. \n\n### Lastly, to give the user actual movie predictions, we can just output the movies corresponding to top k ratings for a user from R_hat (k can be 20 or so).<br><br> Following is the function for the same.","metadata":{}},{"cell_type":"code","source":"def get_k_predictions(predictions, k = 10, user_id = None):\n    \n    # map movies to corresponding estimated ratings for each user\n    user_est_true = defaultdict(list)\n    \n    for uid,iid, _, est_r, _ in predictions:\n        user_est_true[uid].append((iid,est_r))\n        \n    # sort the predictions for each user and retrieve the `k` highest ones\n    for uid, user_ratings in user_est_true.items():\n        user_ratings.sort(key = lambda x :x[1],reverse = True)\n        \n        user_est_true[uid] = user_ratings[:k]\n    \n    if user_id == None:\n        # return for all users\n        return user_est_true\n    else:   \n        return user_est_true[user_id]","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:17.031120Z","iopub.execute_input":"2023-11-16T15:19:17.031382Z","iopub.status.idle":"2023-11-16T15:19:17.039560Z","shell.execute_reply.started":"2023-11-16T15:19:17.031359Z","shell.execute_reply":"2023-11-16T15:19:17.038651Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# top 20 estimated ratings for user id = 12 (user ids : 1 to 7045 valid)\nget_k_predictions(predictions=predictions, k = 20, user_id = '12')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:17.040617Z","iopub.execute_input":"2023-11-16T15:19:17.040960Z","iopub.status.idle":"2023-11-16T15:19:17.314509Z","shell.execute_reply.started":"2023-11-16T15:19:17.040937Z","shell.execute_reply":"2023-11-16T15:19:17.313705Z"},"trusted":true},"execution_count":232,"outputs":[{"execution_count":232,"output_type":"execute_result","data":{"text/plain":"[('1213', 4.369919441138452),\n ('1259', 4.319582773494192),\n ('910', 4.303041096248849),\n ('1617', 4.283768147057547),\n ('1210', 4.212587677233288),\n ('1394', 4.209719977920252),\n ('1188', 4.193736172633765),\n ('8827', 4.186390936705928),\n ('36', 4.146636889811388),\n ('2973', 4.090057029586237),\n ('69757', 4.069130275236678),\n ('898', 4.036136249201578),\n ('6331', 4.035731515521555),\n ('56367', 4.000549844901921),\n ('1673', 3.9901378855132683),\n ('68237', 3.965321541602196),\n ('2997', 3.948230976731987),\n ('6385', 3.9333614679067868),\n ('27815', 3.9175213991837814),\n ('2692', 3.9077057463945333)]"},"metadata":{}}]}]}